{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==1.55.3 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (1.55.3)\n",
      "Requirement already satisfied: httpx==0.27.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: EbookLib in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (0.18)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: PyMuPDF in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (1.25.3)\n",
      "Requirement already satisfied: lxml in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: python-docx in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 8)) (0.8.11)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: certifi in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx==0.27.2->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from EbookLib->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->-r requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: exceptiongroup in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai==1.55.3->-r requirements.txt (line 1)) (1.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 1)) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm_calls # all the interesting code is in here \n",
    "import parsing # all the interesting code is in here \n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "# Add novels to this list\n",
    "books = ['the_stranger.pdf', 'The-Bell-Jar-1645639705._vanilla.xml', 'franz-kafka_metamorphosis.epub']\n",
    "parsed_books = [parsing.parser(book) for book in books] # parse book and split each book by chapters\n",
    "coalesed_books = [parsing.coalesce(book) for book in parsed_books] # combine smaller chapters and information into one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\") # If environmental variable isn't set up, you can replace the right hand side with the api key.\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "modelName = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_level = []\n",
    "outer = 1\n",
    "\n",
    "for book in coalesed_books:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(llm_calls.LiteraryAnalyst(chapter, modelName, client)) # Generate an Analysis on the chapter level for each book\n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(llm_calls.SummarizeNovelLevelAnalysis(novel, modelName, client)) # Synthesize all the chunk-level analyses into one\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = llm_calls.CompareBooks(novel_level, modelName, client) # Comparative Analysis of the novel-level analysis (first time we see different texts )\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "\n",
    "# Generate the Body Paragraphs first -> Introduction (with a strong emphasis on thesis) -> Conclusion\n",
    "\n",
    "body_paragraphs = llm_calls.GenerateBodyParagraphs(comparison, modelName, client) # Pass in Comparison\n",
    "introduction = llm_calls.GenerateIntroduction(body_paragraphs, comparison, modelName, client) # Pass in Previous and Body Paragraph\n",
    "conclusion = llm_calls.GenerateConclusion(introduction, body_paragraphs, comparison, modelName, client) # Pass in Previous and Introduction\n",
    "\n",
    "result = '\\n'.join([introduction, body_paragraphs, conclusion])\n",
    "# result = re.sub(r'\\(body paragraph(?: \\d+(?:, \\s?\\d+)*)?\\)', '', result)\n",
    "\n",
    "\n",
    "with open(\"book_report_final_output.docx\", \"w\") as file:\n",
    "    parsing.save_to_doc(result, 'book_report_final_output.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
