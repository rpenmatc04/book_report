{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==1.55.3 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (1.55.3)\n",
      "Requirement already satisfied: httpx==0.27.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: EbookLib in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (0.18)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: PyMuPDF in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (1.25.3)\n",
      "Requirement already satisfied: lxml in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: python-docx in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 8)) (0.8.11)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from openai==1.55.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: certifi in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpx==0.27.2->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx==0.27.2->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from EbookLib->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->-r requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: exceptiongroup in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai==1.55.3->-r requirements.txt (line 1)) (1.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 1)) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import ebooklib # Parse EPUB\n",
    "import pymupdf # Parse PDF\n",
    "import re \n",
    "import math \n",
    "\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup # Parse HTML, XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/Users/rohanpenmatcha/Library/Python/3.9/lib/python/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "def html_to_str(chapter):\n",
    "    soup = BeautifulSoup(chapter.get_content(), 'html.parser') # Built-in Parser\n",
    "    return soup.get_text()\n",
    "\n",
    "def clean_str(str):\n",
    "    str = str.replace('\\xa0', ' ').replace('\\n', ' ').replace('  ', ' ') # Deal with non-text content. \n",
    "    return str.strip()\n",
    "\n",
    "# Chapter-based chunks. Iterate through pages in pdf until we get to the hyperlinks (table of contents) to get the pages corresponding to chapters\n",
    "# Assumes that the first instance of hyperlinks is the table of contents\n",
    "# If there are no hyperlinks just returns [start, end] pages. \n",
    "def extract_pages_hyperlinks_pdf(path):\n",
    "    doc = pymupdf.open(path)\n",
    "    hyperlinks = []\n",
    "    hyperlinks.append(0) \n",
    "    for page in doc:\n",
    "        links = page.get_links()  # Extract all links\n",
    "        need_to_sort = False\n",
    "        if len(links) > 0: # Table of Contents\n",
    "            for link in links:\n",
    "                temp = link.get(\"page\") \n",
    "                if temp not in hyperlinks:\n",
    "                    if len(hyperlinks) > 0:\n",
    "                        if temp < hyperlinks[-1]:\n",
    "                            need_to_sort = True\n",
    "                        if (temp - 2) < hyperlinks[-1]: # each page is ~500 tokens max. \n",
    "                            continue\n",
    "                    hyperlinks.append(temp)\n",
    "            hyperlinks.append(len(doc))\n",
    "            if need_to_sort:\n",
    "                sorted(hyperlinks) # When the hyperlinks are out of order\n",
    "            return doc, hyperlinks\n",
    "\n",
    "    hyperlinks.append(len(doc))\n",
    "    doc, hyperlinks\n",
    "\n",
    "def parse_epub(path): \n",
    "    book = epub.read_epub(path)\n",
    "    items = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT)) # ITEM_DOCUMENT is flag for actual words\n",
    "    chapters = []\n",
    "    for item in items:\n",
    "        temp = clean_str(html_to_str(item))\n",
    "        # temp will be empty if it's the item is non-content data\n",
    "        if temp:\n",
    "            chapters.append(temp)\n",
    "    return chapters\n",
    "\n",
    "def parse_pdf(path): \n",
    "    # Create Chunks Based on \"chapters\" via Hyperlink pages. \n",
    "    # If Hyperlinks don't exist\n",
    "    doc, hyperlinks = extract_pages_hyperlinks_pdf(path)\n",
    "    chapters = []\n",
    "    for i in range(0, len(hyperlinks) - 1):\n",
    "        text = []\n",
    "        for pages in range(hyperlinks[i], hyperlinks[i + 1]):\n",
    "            text.append(clean_str(doc[pages].get_text()))\n",
    "        chapters.append(''.join(text))\n",
    "    if len(hyperlinks) == 2:\n",
    "        chapters = generate_equal_chunks(chapters)\n",
    "    return chapters\n",
    "\n",
    "def parse_xml(path):\n",
    "    soup = BeautifulSoup(open(path, \"r\", encoding=\"utf-8\").read(), 'lxml')\n",
    "    title_tag = soup.find(\"title\")\n",
    "    chapters = []\n",
    "\n",
    "    if title_tag:\n",
    "        chapters.append(title_tag.text.strip())\n",
    "    content_tags = soup.find_all(\"content:encoded\") \n",
    "    for content in content_tags: \n",
    "        temp = content.text\n",
    "        if temp.endswith(\"]]>\"):\n",
    "            temp = temp[:-3]\n",
    "        temp = clean_str(temp)\n",
    "        if temp:\n",
    "            chapters.append(temp)\n",
    "    return chapters\n",
    "\n",
    "def parser(path):\n",
    "    file, extension = os.path.splitext(path)\n",
    "    if extension == \".epub\":\n",
    "        return parse_epub(path)\n",
    "    elif extension == \".pdf\":\n",
    "        return parse_pdf(path)\n",
    "    elif extension == '.xml':\n",
    "        return parse_xml(path)\n",
    "    else: \n",
    "        file = open(path, \"r\", encoding = \"utf-8\")\n",
    "        return file.read()\n",
    "\n",
    "def coalesce(book, min_length=15000):\n",
    "    out = []\n",
    "    for str in book:\n",
    "        # Combing smaller chapters or extra non-chapter information into same call\n",
    "        if len(out) > 0 and (len(out[-1]) + len(str) < min_length or len(str) > 10 * len(out[-1])):\n",
    "            temp = out[-1]\n",
    "            out[-1] = temp + \" \" + str\n",
    "        else:\n",
    "            out.append(str)\n",
    "    return out\n",
    "\n",
    "def generate_equal_chunks(coalesed_books, num_calls = 10):\n",
    "    output = []\n",
    "    for book in coalesed_books:\n",
    "        min_size = 0\n",
    "        for chapter in book:\n",
    "            min_size += len(chapter)\n",
    "        min_size = math.ceil(float(min_size) / num_calls) # num_calls of each min_size characters (tokens ~ characters / 4)\n",
    "\n",
    "        combined = []\n",
    "        current = \"\"\n",
    "\n",
    "        for chapter in book:\n",
    "            if len(current) + len(chapter) <= min_size:\n",
    "                current = current + \" \" + chapter\n",
    "            else: \n",
    "                combined_string = current + \" \" + chapter\n",
    "                split = min_size\n",
    "                punctuation = {'.', '!', '?'}\n",
    "                for chr in range(min_size - 1, -1, -1):\n",
    "                    if combined_string[chr] in punctuation:\n",
    "                        split = chr + 1\n",
    "                        break\n",
    "\n",
    "                combined.append(combined_string[:split].strip())\n",
    "                current = combined_string[split:]\n",
    "        if current: \n",
    "            combined.append(current.strip()) \n",
    "        if combined: \n",
    "            output.append(combined)\n",
    "    return output\n",
    "\n",
    "# parsed_books have removed all non-text from each file\n",
    "# each index is a list of lists so that each chunk represents a chapter or split (information about the book)\n",
    "# https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Four Approaches\n",
    "# gpt-4o only unless otherwise stated \n",
    "\n",
    "# Test 0: \n",
    "# Generate Analysis for Each Novel \n",
    "# Generate Comparitive Analysis for the Individual Novel Analyses\n",
    "# Generate 5-paragraph Report with One Single Call\n",
    "\n",
    "# Test 1:  \n",
    "# Generate analysis for each chunk independently (granularity of at least one chapter per call)\n",
    "# Novel-level analysis to coalesce the result of each chunk into one analysis\n",
    "# Comparative Analysis of the 3 Novel-level analyses \n",
    "# Generate 5-paragraph Report with One Single Call\n",
    "\n",
    "# Test 2:\n",
    "# PT1: Generate each chunk independently (split so chunks are equal in size) \n",
    "# PT2: Generate each chunk-analysis so that they are given the context of previous analyses. - incremental merging \n",
    "\n",
    "# Test 3:\n",
    "# Select the best of Test 0 - 2\n",
    "# Novel-level analysis by passing in two chunks at a time and combining until there's one left (mergesort approach) - hierarchal merging\n",
    "\n",
    "\n",
    "# Test 4: \n",
    "# Select the best of Test 0-3\n",
    "# Generate 5-Paragraph Report with multiple calls (Body Paragraphs -> Thesis -> Introduction -> Conclusion)\n",
    "\n",
    "# Test 5: \n",
    "# Select the best of Test 0-4\n",
    "# gpt 3.5 for chunk level, gpt4-o for rest \n",
    "# Run the best of the previous tests using different company models \n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "modelName = 'gpt-4o'\n",
    "\n",
    "def LiteraryAnalyst(excerpt, modelName, client = client):\n",
    "\n",
    "  system = \"You are a Literary Analyst focused on the theme of social isolation. Identify multiple passages, quotes, and examples that display this theme in the excerpt.\"\n",
    "\n",
    "  prompt = f\"Analyze the following excerpt, specifically about the theme of social isolation. Return direct quotes and examples from the text, and explain how they relate to social isolation: \\n {excerpt}\"\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def LiteraryAnalystIncremental(pastResponses, excerpt, modelName, client = client):\n",
    "  pastResponses = '\\n'.join(pastResponses)\n",
    "  \n",
    "  system = \"You are a Literary Analyst focused on the theme of social isolation. Identify multiple passages, quotes, and examples that display this theme in the excerpt.\"\n",
    "\n",
    "  prompt = f\"Below are analyses of previous sections of the text regarding the theme of social isolation:\\n\\n{pastResponses}\\n\\nNow, analyze the following excerpt in the context of these past responses. Identify direct quotes and examples that display social isolation, and explain how they connect to or expand upon the theme as established in prior sections:\\n\\n{excerpt}\"\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def SummarizeNovelLevelAnalysis(chunks, modelName, client = client):  \n",
    "  analyses = '\\n'.join(chunks)\n",
    "\n",
    "  system = \"You are a Literary Analyst focused on synthesizing analysis about social isolation. Your goal is to return a novel-level summary about how this work \" \\\n",
    "  \"displays the theme of social isolation. Reference the most important quotes, examples, and passages in the chunk-level analyses, and explain their significance.\"\n",
    "\n",
    "  prompt = f\"Below are chunk-level analyses produced for the novel. Please synthesize these into a single, detailed summary focused on the theme of social isolation. Return important quotes and explanations that highlight the author's perspective on social isolation. If the chunk analyses do not contain a particular detail or example, do not make it up. Generate the summary only on the chunk-level analyses provided below: \\n {analyses}\"\n",
    "  \n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def SummarizeNovelLevelAnalysisHierarchical(chunk_1, chunk_2, modelName, client = client):  \n",
    "\n",
    "  system = \"You are a Literary Analyst focused on synthesizing analysis about social isolation. Your goal is to return a summary about how this work \" \\\n",
    "  \"displays the theme of social isolation. Reference the most important quotes, examples, and passages in the chunk-level analyses, and explain their significance.\"\n",
    "\n",
    "  prompt = f\"Below are two chunk-level analyses produced for the novel. Please synthesize these into a single, detailed summary focused on the theme of social isolation. Return important quotes and explanations that highlight the author's perspective on social isolation. If the chunk analyses do not contain a particular detail or example, do not make it up. Generate the summary only on the chunk-level analyses provided below: \\n {chunk_1} \\n {chunk_2}\"\n",
    "  \n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def CompareBooks(novels, modelName, client = client):\n",
    "  compare_analyses = '\\n'.join(novels)\n",
    "\n",
    "  system = \"You are an expert at comparing literature. Create a detailed comparison of how different novels approach the theme of social isolation, focusing on the author's point of view, as well as supporting quotations, passages, and corresponding explanations.\"\n",
    "  \n",
    "  prompt = f\"Compare and contrast how these following novels handle the theme of social isolation. The following are analyses of how each novel handles the theme. Identify how each text handles the theme of social isolation and how they differ approach, perspective, and resolution of this theme by including several specific examples. If the novel analyses do not contain a particular detail or example, do not make it up. Generate the summary only using analyses provided below: \\n {compare_analyses}\"\n",
    "\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def GenerateReport(comparison, modelName, client = client):\n",
    "  system = \"You are an expert book report writer with a focus on comparative literary analysis. Your task is to create a detailed book report analyzing how different books explore the theme of social isolation by providing detailed comparisons, highlighting themes, and discussing the techniques and views of the authors.\"\n",
    "  \n",
    "  prompt = f\"\"\"\n",
    "  Write a five-paragraph comparative book report based on a Comparative Analysis to explain how the works handle the theme of social isolation.\"\n",
    "\n",
    "  Structure of Report: \n",
    "  Introduction Paragraph: Introduce the books and end with a strong thesis statement about how each book deals with social isolation\n",
    "  First Body Paragraph: Explain how the first book deals with the topic of social isolation with at least 1-2 direct references to the text.\n",
    "  Second Body Paragraph: Explain how the second book deals with the topic of social isolation with at least 1-2 direct references to the text.\n",
    "  Third Body Paragraph: Explain how the third book deals with the topic of social isolation with at least 1-2 direct references to the text.\n",
    "  Conclusion Paragraph: Summarize the key points in the body paragraphs as well as restating the thesis. \n",
    "\n",
    "  Requirements: \n",
    "  Each body paragraph must include direct and accurate quotations from the book. \n",
    "  The report should focus on the differences and similarities in how each author views and expresses the theme of social isolation.\n",
    "  The report should be in a professional tone and digestible.\n",
    "\n",
    "  The Comparative Analysis is included below: \\n {comparison}\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model = modelName,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def CompareBookReports(report1, report2, modelName, client=client):\n",
    "  system = \"\"\" \n",
    "      You are an expert literary analyst. Compare two book reports based on the following three factors: \n",
    "      the depth of analysis and evidence, writing clarity, and logical coherence. \n",
    "      Evaluate both reports carefully.\"\n",
    "      Return only '0' if the first is better or '1' if the second is better. \n",
    "      \"\"\"\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "      Here are two book reports analyzing how the same books explore the theme of social isolation. \n",
    "      Evaluate them independently based on depth of analysis, writing clarity, and logical coherence. \n",
    "      After considering both carefully, determine which one is stronger overall. \n",
    "      Provide your answer as '0' if Report 1 is better or '1' if Report 2 is better. \n",
    "      The positions are irrelevant .\\n\\n\n",
    "      Book Report 1:\\n {report1} \\n\\n Book Report 2:\\n {report2}.\n",
    "      \"\"\"\n",
    "\n",
    "  print(prompt)\n",
    "  completion = client.chat.completions.create(\n",
    "      model=modelName,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system},\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "def GenerateBodyParagraphs(comparison, modelName, client):\n",
    "\n",
    "    system = \"You are an expert in literary comparison. Your goal is to write three body paragraphs that each focus solely on how one of the three books addresses the theme of social isolation. \" \\\n",
    "    \"Each paragraph must include at least one to two direct quotes or passages from the provided analysis only if available.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Below is a comparative analysis of three novels' approaches to social isolation. \n",
    "        Using only this analysis, write three body paragraphs:\n",
    "        Body Paragraph 1: Focus on the first book, analyzing how it treats social isolation with supporting quotes.\n",
    "        Body Paragraph 2: Focus on the second book, analyzing how it treats social isolation with supporting quotes.\n",
    "        Body Paragraph 3: Focus on the third book, analyzing how it treats social isolation with supporting quotes.\n",
    "        Each paragraph should focus on one novel's themes and views, with direct quotes only if available.\n",
    "        Comparative Analysis: \\n{comparison}\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=modelName,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def GenerateIntroduction(body_paragraphs, comparison, modelName, client):\n",
    "\n",
    "    system = \"You are an expert in literary comparison. Your goal is to write an introduction paragraph with a strong thesis for a comparative book report on \" \\\n",
    "    \"social isolation across three works. The introduction must reference the already written body paragraphs.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Below is the following body paragraphs already written: \\n\n",
    "        {body_paragraphs} \\n \\n \n",
    "        Below is the comparative analysis of the three novels for additional context: \\n\n",
    "        {comparison} \\n \\n\n",
    "        Write a single introduction paragraph with the following goals: \\n\n",
    "        1. Clear thesis of how the theme of social isolation is handled in the three books by referencing the analysis in the body paragraphs, \n",
    "        2. Mention the title of the three books and the authors.\n",
    "        3. Describe the main points to be detailed in the body paragraphs.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=modelName,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def GenerateConclusion(introduction, body_paragraphs, comparison, modelName, client):\n",
    "\n",
    "    system =  f\"\"\"You are a literary analyst. Your goal is to write a single conclusion paragraph with the following goals: \\n \n",
    "        1. Synthesize the key similarities and differences among the three novels regarding the theme of social isolation\n",
    "        2. Restate the thesis in a different way, and \n",
    "        3. Final thought on social isolation.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Below is the introduction already written: \\n\n",
    "        {introduction} \\n \\n \n",
    "        Below is the three body paragraphs: \\n\n",
    "        {body_paragraphs} \\n \\n\n",
    "        Finally, here is the generated comparative analysis for the three texts for extra reference: \\n\n",
    "        {comparison} \\n \\n\n",
    "        Write a single conclusion paragraph with the following goals: \\n\n",
    "        1. Summarize the main points about similarities and differences from the body paragraphs\n",
    "        2. Restate the thesis in a different way  \n",
    "        3. Leave a final thought on why these comparisons matter and about social isolation.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=modelName,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def read_doc(path):\n",
    "  doc = Document(path)\n",
    "  return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "def save_to_doc(report, filename):\n",
    "    doc = Document()\n",
    "    paragraph = report.split('\\n')\n",
    "    heading = doc.add_heading(\"Comparative Analysis\", level=1)\n",
    "    heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "    for text in paragraph:\n",
    "      if not text: \n",
    "        continue\n",
    "      doc.add_paragraph(\"       \" + text)\n",
    "    doc.save(filename)\n",
    "\n",
    "\n",
    "reports = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Finished Book 1 \n",
      "\n",
      "9\n",
      "Finished Book 2 \n",
      "\n",
      "3\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 0 \n",
    "\n",
    "test_version_0 = []\n",
    "outer = 1\n",
    "for book in coalesed_books:\n",
    "    temp = LiteraryAnalyst('\\n'.join(book), modelName, client)\n",
    "    test_version_0.append(temp)\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(test_version_0, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "result = GenerateReport(comparison, modelName, client)\n",
    "result = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v0.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v0.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished iteration 10 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "\n",
    "chunk_level = []\n",
    "outer = 1\n",
    "\n",
    "for book in coalesed_books:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(LiteraryAnalyst(chapter, modelName, client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(SummarizeNovelLevelAnalysis(novel, modelName, client))\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "result = GenerateReport(comparison, modelName, client)\n",
    "result = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v1.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v1.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2 - equal chunks \n",
    "\n",
    "equal_chunks = generate_equal_chunks(coalesed_books)\n",
    "chunk_level = []\n",
    "\n",
    "outer = 1\n",
    "for book in equal_chunks:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(LiteraryAnalyst(chapter, modelName, client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(SummarizeNovelLevelAnalysis(novel, modelName, client))\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "result = GenerateReport(comparison, modelName, client)\n",
    "result = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v2_1.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v2_1.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2 (Incremental Merging)  \n",
    "equal_chunks = generate_equal_chunks(coalesed_books)\n",
    "chunk_level = []\n",
    "\n",
    "outer = 1\n",
    "for book in equal_chunks:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        if len(temp) == 0:\n",
    "          temp.append(LiteraryAnalyst(chapter, modelName, client)) \n",
    "        else: \n",
    "          temp.append(LiteraryAnalystIncremental(temp, chapter, modelName, client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(SummarizeNovelLevelAnalysis(novel, modelName, client))\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "result = GenerateReport(comparison, modelName, client)\n",
    "result = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v2_2.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v2_2.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing all the essays to get the best one \n",
    "\n",
    "def get_best_output(outputs): \n",
    "    while len(outputs) > 1:\n",
    "         # Comparison Based Judger on Two Reports until One is Left\n",
    "        temp = CompareBookReports(outputs[0], outputs[1], modelName, client=client)\n",
    "        saved = outputs[0]\n",
    "        if '0' in temp[0:5]:\n",
    "            saved = outputs[0]\n",
    "        elif '1' in temp[0:5]: \n",
    "            saved = outputs[1]\n",
    "        else: \n",
    "            print(\"Error\")\n",
    "        print(saved)\n",
    "        outputs = outputs[2:]\n",
    "        outputs.append(saved)\n",
    "        \n",
    "    return outputs[0] \n",
    "\n",
    "result = [get_best_output(reports) for i in range(20)] # Found Test 1 was the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished iteration 10 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3 (Hierarchical Merging)\n",
    "\n",
    "chunk_level = []\n",
    "outer = 1\n",
    "\n",
    "for book in coalesed_books:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(LiteraryAnalyst(chapter, modelName, client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    temp = novel.copy() \n",
    "    while (len(temp) > 1):\n",
    "        temp.append(SummarizeNovelLevelAnalysisHierarchical(temp[0], temp[1], modelName, client))\n",
    "        temp = temp[2:]\n",
    "\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "result = GenerateReport(comparison, modelName, client)\n",
    "result = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', result)\n",
    "\n",
    "reports.append(result) \n",
    "\n",
    "with open(\"five_page_report_call_v3.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v3.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_best_output(reports) # Test 1 was still the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished iteration 10 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4 - 3 Report Generation Calls Instead\n",
    "\n",
    "chunk_level = []\n",
    "outer = 1\n",
    "\n",
    "for book in coalesed_books:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(LiteraryAnalyst(chapter, modelName, client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(SummarizeNovelLevelAnalysis(novel, modelName, client))\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "body_paragraphs = GenerateBodyParagraphs(comparison, modelName, client)\n",
    "body_paragraphs = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', body_paragraphs)\n",
    "introduction = GenerateIntroduction(body_paragraphs, comparison, modelName, client)\n",
    "introduction = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', introduction)\n",
    "conclusion = GenerateConclusion(introduction, body_paragraphs, comparison, modelName, client)\n",
    "conclusion = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', conclusion)\n",
    "\n",
    "result = '\\n'.join([introduction, body_paragraphs, conclusion])\n",
    "# result = re.sub(r'\\(body paragraph(?: \\d+(?:, \\s?\\d+)*)?\\)', '', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v4.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_call_v4.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished iteration 9 \n",
      "\n",
      "Finished iteration 10 \n",
      "\n",
      "Finished Book 1 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished iteration 3 \n",
      "\n",
      "Finished iteration 4 \n",
      "\n",
      "Finished iteration 5 \n",
      "\n",
      "Finished iteration 6 \n",
      "\n",
      "Finished iteration 7 \n",
      "\n",
      "Finished iteration 8 \n",
      "\n",
      "Finished Book 2 \n",
      "\n",
      "Finished iteration 0 \n",
      "\n",
      "Finished iteration 1 \n",
      "\n",
      "Finished iteration 2 \n",
      "\n",
      "Finished Book 3 \n",
      "\n",
      "Finished Summarizing Book 1 \n",
      "\n",
      "Finished Summarizing Book 2 \n",
      "\n",
      "Finished Summarizing Book 3 \n",
      "\n",
      "Finished Comparing The Three Books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 5 - cheaper models for analysis and more expensive models for summary \n",
    "\n",
    "chunk_level = []\n",
    "outer = 1\n",
    "\n",
    "for book in coalesed_books:\n",
    "    temp = []\n",
    "    for i, chapter in enumerate(book):\n",
    "        temp.append(LiteraryAnalyst(chapter, 'gpt-3.5-turbo', client)) \n",
    "        print(f\"Finished iteration {i} \\n\")\n",
    "    print(f\"Finished Book {outer} \\n\")\n",
    "    chunk_level.append(temp)\n",
    "    outer += 1\n",
    "\n",
    "novel_level = []\n",
    "outer = 1\n",
    "for novel in chunk_level:\n",
    "    novel_level.append(SummarizeNovelLevelAnalysis(novel, modelName, client))\n",
    "    print(f\"Finished Summarizing Book {outer} \\n\")\n",
    "    outer += 1\n",
    "\n",
    "comparison = CompareBooks(novel_level, modelName, client)\n",
    "print(f\"Finished Comparing The Three Books \\n\")\n",
    "\n",
    "body_paragraphs = GenerateBodyParagraphs(comparison, modelName, client)\n",
    "body_paragraphs = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', body_paragraphs)\n",
    "introduction = GenerateIntroduction(body_paragraphs, comparison, modelName, client)\n",
    "introduction = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', introduction)\n",
    "conclusion = GenerateConclusion(introduction, body_paragraphs, comparison, modelName, client)\n",
    "conclusion = re.sub(r'\\*(.*?)\\*', r'\"\\1\"', conclusion)\n",
    "\n",
    "result = '\\n'.join([introduction, body_paragraphs, conclusion])\n",
    "# result = re.sub(r'\\(body paragraph(?: \\d+(?:, \\s?\\d+)*)?\\)', '', result)\n",
    "\n",
    "reports.append(result)\n",
    "\n",
    "with open(\"five_page_report_call_v5.docx\", \"w\") as file:\n",
    "    save_to_doc(result, 'five_page_report_final_call_v5.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
